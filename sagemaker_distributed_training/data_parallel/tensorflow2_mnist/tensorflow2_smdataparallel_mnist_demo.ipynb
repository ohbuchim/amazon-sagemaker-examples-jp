{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow2 と SMDataParallel を使った MNIST のデータ並列分散学習\n",
    "\n",
    "SMDataParallelは、Amazon SageMaker の新しい機能で、深層学習モデルをより速く、より安価に学習することができます。SMDataParallelは、TensorFlow2、PyTorch、MXNet 用の分散データ並列学習フレームワークです。\n",
    "\n",
    "このノートブックでは、MNIST データセットを使用して SageMaker で TensorFlow2 と SMDataParallel を使用する方法をご紹介します。\n",
    "\n",
    "詳細に関しては以下のリンクをご参照ください。\n",
    "1. [TensorFlow in SageMaker](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html)\n",
    "2. [SMDataParallelTensorFlow API Specification](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-use-api.html)\n",
    "3. [Getting started with SMDataParallel on SageMaker] < LINK TO BE ADDED >\n",
    "\n",
    "**NOTE:** このノートブックでは SageMaker Python SDK v2.X. を使用しています。\n",
    "\n",
    "### Dataset\n",
    "この例は MNIST データセットを使用しています。MNIST は、手書き数字の分類に広く使われているデータセットです。MNIST データセットは、ラベル付けされた 28x28 ピクセルの手書き数字のグレースケール画像 70,000枚で構成されています。データセットは 60,000枚の学習画像と 10,000枚のテスト画像に分割されています。0 から 9 までの 10個のクラスがあります。\n",
    "\n",
    "### SageMaker execution roles\n",
    "IAMロール ARN は、トレーニングやデータへのアクセス権を与えるために使用されます。これらの作成方法については、[Amazon SageMaker ロール](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) を参照してください。ノートブックインスタンス、トレーニング、ホスティングに複数のロールを使用する場合は、sagemaker.get_execution_role() を適切な IAM ロールの ARN 文字列に置き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMDataParallel を使ったモデルの学習\n",
    "\n",
    "### 学習スクリプト\n",
    "\n",
    "`train_tensorflow_smdataparallel_mnist.py` スクリプトは、SMDataParallel の `DistributedGradientTape` を使用して SageMaker モデルをトレーニングするために必要なコードを提供します。この学習スクリプトは、SageMaker の外部で実行する TensorFlow2 学習スクリプトに非常に似ていますが、SMDataParallel で実行するように修正されています。SMDataParallel の TensorFlow クライアントは、ネイティブの `DistributedGradientTape` に代わるものを提供します。ネイティブTF2 スクリプトでの SMDataParallel の使用方法の詳細については、[SMDataParallel チ ュートリアル](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp.html#data-parallel-modify-sdp-tf2) を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize code/train_tensorflow_smdataparallel_mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker TensorFlow Estimator function options\n",
    "\n",
    "次のコードブロックでは、異なるインスタンスタイプ、インスタンス数、および分散学習の設定を使用するように、estimator を設定します。また、前のセルで確認した学習スクリプトも指定します。\n",
    "\n",
    "\n",
    "**インスタンスタイプ**\n",
    "\n",
    "SMDataParallel は以下のインスタンスタイプのみで SageMaker のモデル学習に対応しています。\n",
    "1. ml.p3.16xlarge\n",
    "1. ml.p3dn.24xlarge [Recommended]\n",
    "1. ml.p4d.24xlarge [Recommended]\n",
    "\n",
    "**インスタンス数**\n",
    "\n",
    "SMDataParallel によって最高のパフォーマンスを得るには少なくとも 2つのインスタンスを使う必要がありますが、動作確認のために 1つのインスタンスのみを使用することも可能です。\n",
    "\n",
    "**分散学習の設定**\n",
    "\n",
    "DDP モードを使用するには `smdistributed dataparallel` を使用するように `distribution` strategy を設定する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = TensorFlow(\n",
    "                        base_job_name='tensorflow2-smdataparallel-mnist',\n",
    "                        source_dir='code',\n",
    "                        entry_point='train_tensorflow_smdataparallel_mnist.py',\n",
    "                        role=role,\n",
    "                        py_version='py37',\n",
    "                        framework_version='2.3.1',\n",
    "                        # For training with multinode distributed training, set this count. Example: 2\n",
    "                        instance_count=2,\n",
    "                        # For training with p3dn instance use - ml.p3dn.24xlarge\n",
    "                        instance_type= 'ml.p3.16xlarge',\n",
    "                        sagemaker_session=sagemaker_session,\n",
    "                        # Training using SMDataParallel Distributed Training Framework\n",
    "                        distribution={'smdistributed':{\n",
    "                                            'dataparallel':{\n",
    "                                                    'enabled': True\n",
    "                                             }\n",
    "                                      }}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論\n",
    "\n",
    "学習されたモデルができたので、モデルをホストするエンドポイントをデプロイします。エンドポイントをデプロイした後、推論リクエストでテストすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = estimator.model_data\n",
    "print(\"Using this model: {}\".format(model_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルオブジェクトの作成\n",
    "SageMaker SDK の TensorFlowModel を使ってモデルオブジェクトを定義し、 estimator と entry_point からモデルを渡します。関数はモデルをロードし、GPU が利用可能であれば GPU を使用するように設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "model = TensorFlowModel(model_data=model_data, role=role, framework_version='2.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルをエンドポイントにデプロイ\n",
    "model.deploy 関数を使用して predictor を作成します。オプションでインスタンス数とインスタンスタイプの両方を変更することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the test set\n",
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.keras.datasets.mnist.load_data(\n",
    "    path='mnist.npz'\n",
    ")\n",
    "\n",
    "_, (test_imgs, test_labels) = dataset\n",
    "\n",
    "# Randomly select 16 images from the test images\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "mask = random.sample(range(0, len(test_imgs)), 16)\n",
    "mask = np.array(mask, dtype=np.int8)\n",
    "samples = test_imgs[mask]\n",
    "\n",
    "# Inspect sample images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=8, sharex=True, sharey=True)\n",
    "for i, row in enumerate(ax):\n",
    "    for j, col in enumerate(row):\n",
    "        col.imshow(samples[8*i+j].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the samples to the endpoint for inference\n",
    "samples = np.expand_dims(samples, axis=3)\n",
    "outputs = predictor.predict(samples)['predictions']\n",
    "outputs = np.array(outputs, dtype=np.float32)\n",
    "\n",
    "print(\"Predictions: \")\n",
    "print(np.argmax(outputs, axis=1))\n",
    "\n",
    "print(\"Ground Truth: \")\n",
    "print(test_labels[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エンドポイントの削除\n",
    "エンドポイント への課金を止めるために、これ以上推論を試したり、エンドポイントを使う予定がない場合は、エンドポイントを削除してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
